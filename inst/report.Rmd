---
title: "Main Concept Analysis: report"
output: pdf_document
urlcolor: blue
params:
  summary_table: NA
  norms: NA 
  current_score: NA
  stim: NA
  scoring: NA
  norm_var: NA
  num_concepts: NA
  start_time: NA 
  name: NA
  notes: NA
header-includes:
    - \usepackage{booktabs}
    - \usepackage{tabu}
    - \usepackage{longtable}
    - \usepackage{float}
    - \usepackage[default]{sourcesanspro}
    - \usepackage[T1]{fontenc}
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
options(knitr.kable.NA = '-')
shiny::setProgress(0.1)
```


### Summary of measure

Main Concept Analysis (MCA) is a hybrid discourse measure that provides some information on micro-linguistic features of the discourse sample as well as more macro-linguistic features about the overall adequacy of the discourse sample to communicate an intended message. Main concept checklists for several widely used tasks (including picture description, picture sequence, story retell, and procedural stimuli) have been developed based on discourse samples of control speakers (Richardson & Dalton, 2016; 2020). Each main concept consists of several essential elements, corresponding to the subject, main verb, object (if appropriate), and any subordinate clauses (Nicholas & Brookshire, 1995). The main concept is assigned one of 5 codes depending on the accuracy (are the essential elements accurate?) and completeness (are essential elements present?) of the production. 

### Coding

- Accurate & Complete (AC): contains all elements of the main concept on the checklist with no incorrect information
- Accurate & Incomplete (AI): contains no incorrect information, but leaves out at least one essential element of the main concept on the checklist
- Inaccurate & Complete (IC): contains at least one incorrect piece of essential information (e.g., “knight” for “prince”) but includes all essential elements of the main concept on the checklist
- Inaccurate & Incomplete (II): clearly corresponds with a main concept on the checklist but includes at least one incorrect essential element and fails to include at least one essential element
- Absent (AB): did not produce the main concept

### Main Concept Composite Scoring (Richardson & Dalton, 2016)	

- Accurate & Complete (AC): 3 Points
- Accurate & Incomplete (AI): 2 Points
- Inaccurate & Complete (IC): 2 Points
- Inaccurate & Incomplete (II): 1 Point
- Absent (AB): 0 Points
				
MC codes were transformed to numeric scores using the formula adapted from Kong (2009): AC(3) + AI(2) + IC(2) + II(1) + AB(0) = MC score.

```{r, include = FALSE}
print("pre")
```

### Results

This test was completed by `r params$name` and scored on `r format(params$start_time, format="%B %d %Y %R %Z")`. These results are specific to the ***`r stringr::str_to_title(paste(unlist(strsplit(params$stim, split = "_")), collapse = " "))` stimulus.*** 

**Main Concept Composite Score:** The main concept score for this person is `r params$summary_table[1,3]`. This is in the `r params$summary_table[1,4]` percentile of persons with aphasia (PWAs), meaning that `r params$summary_table[1,4]` percent of the PWAs in the sample scored lower than or equal to your patient/participant. This is in the `r params$summary_table[1,5]` percentile of controls, meaning that `r params$summary_table[1,5]` percent of controls in the sample scored lower than or equal to your patient/participant. 

**Accurate and Complete (AC) Codes:** Your patient/participant produced `r params$summary_table[2,2]` AC codes out of `r params$num_concepts` main concepts. This is in the `r params$summary_table[2,4]` percentile of persons with aphasia (PWAs), meaning that `r params$summary_table[2,4]` percent of the PWAs in the sample scored scored lower than or equal to your patient/participant. This is in the `r params$summary_table[2,5]` percentile of controls, meaning that `r params$summary_table[2,5]` percent of controls in the sample scored scored lower than or equal to your patient/participant. 

**Accurate and Incomplete (AI) Codes:** Your patient/participant produced `r params$summary_table[3,2]` AI codes out of `r params$num_concepts` main concepts.

**Inaccurate and Complete (IC) Codes:** Your patient/participant produced `r params$summary_table[4,2]` IC codes out of `r params$num_concepts` main concepts..  

**Inaccurate and Complete (II) Codes:** Your patient/participant produced `r params$summary_table[5,2]` II codes out of `r params$num_concepts` main concepts.

**Absent (AB) Codes:** `r params$summary_table[6,2]` were absent/not attempted out of `r params$num_concepts` main concepts. 

Attempts: Your patient/participant attempted to produce `r params$summary_table[7,2]` of of `r params$num_concepts` main concepts for this task. This is in the `r params$summary_table[7,4]` percentile of persons with aphasia (PWAs), meaning that `r params$summary_table[7,4]` percent of the PWAs in the sample had equal to or fewer attempts than your patient/participant. This is in the `r params$summary_table[7,5]` percentile of controls, meaning that `r params$summary_table[7,5]` percent of controls in the sample had  equal to or fewer attempts than your patient/participant. 

*Main Concept efficiency scores are only available if a time was entered into the app prior to scoring.*

Accurate and Complete Codes per minute (AC/min): AC/min is a measure of discourse efficiency, specifically how many accurate and complete main concepts were produced per minute. Derived efficiency measures are “useful in examining the effort needed by the speaker to produce discourse and the consequent effort needed by the listener in receiving the information effectively” (Armstrong, 2000). Your patient/participant produced `r params$summary_table[8,2]`. This is in the `r params$summary_table[8,4]` percentile of persons with aphasia (PWAs), meaning that `r params$summary_table[8,4]` percent of the PWAs in the sample produced equal to or fewer AC concepts per minute than your patient/participant. This is in the `r params$summary_table[8,5]` percentile of controls, meaning that `r params$summary_table[8,5]` percent of controls in the sample produced equal to or fewer AC concepts per minute than your patient/participant. 

```{r, echo = F, message = F}
kableExtra::kbl(params$summary_table,
                format = "latex",
                booktabs = TRUE,
                caption = "Summary of results from MCA") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
shiny::setProgress(0.3)
message("early")
```

**About this table:**

- *Column 1 lists the following discourse variables: Main Concept Composite score, Accurate and Complete (AC) concepts, Accurate and Incomplete (AI) concepts, Inaccurate and Complete (IC) concepts, Inaccurate and Incomplete (II) concepts, Absent concepts, Main Concept Attempts, and Accurate and Complete concepts per minute (AC/min).*

- *Column 2 shows the counts for the discourse variables. *

- *Column 3 shows the calculated score for the discourse variables, based upon the scoring system for either Dalton & Richardson (2016) or Kong (2009) (select scoring system option at bottom of table).*

- *Column 4 shows a percentile score that corresponds to the vertical red dashed line and the orange density plot and is the percentage of scores for the sample of people with aphasia that are lower than your patient’s/participant’s score.*

- *Column 5 shows a percentile score that corresponds to the vertical red dashed line and the purple density plot and is the percentage of control scores that are lower than your patient’s/participant’s score. Columns 4 and 5 are only available when using the Dalton & Richardson (2016) scoring system.*

\newpage

```{r, echo=F, fig.height=5.5, fig.width=7, warning = F, message = FALSE, fig.cap="Results relative to normative samples"}
library(cowplot)
message(
  as.numeric(c(
               params$summary_table[[1,3]], # composite
               params$summary_table[[2,2]], # AC
               params$summary_table[[7,2]],
               readr::parse_number(params$summary_table[[8,2]])
             ))
)

message("start plots")
p1 <- get_plot_report(norms = params$norms,
             current_score = as.numeric(c(
               params$summary_table[[1,3]], # composite
               params$summary_table[[2,2]], # AC
               params$summary_table[[7,2]],
               readr::parse_number(params$summary_table[[8,2]])
             )
             ),
             stim = params$stim,
             scoring = "dalton_richardson",
             norm_var = "MC COMPOSITE",
             basesize=11)
message("p1 done")
p2 <- get_plot_report(norms = params$norms,
             current_score = as.numeric(c(
               params$summary_table[[1,3]], # composite
               params$summary_table[[2,2]], # AC
               params$summary_table[[7,2]],
               readr::parse_number(params$summary_table[[8,2]])
             )
             ),
             stim = params$stim,
             scoring = "dalton_richardson",
             norm_var = "AC",
             basesize=11)
  message("p2 done")

p3 <- get_plot_report(norms = params$norms,
             current_score = as.numeric(c(
               params$summary_table[[1,3]], # composite
               params$summary_table[[2,2]], # AC
               params$summary_table[[7,2]],
               readr::parse_number(params$summary_table[[8,2]])
             )
             ),
             stim = params$stim,
             scoring = "dalton_richardson",
             norm_var = "MC Attempts",
             basesize=11)
message("p3 done")

p4 <- get_plot_report(norms = params$norms,
             current_score = as.numeric(c(
               params$summary_table[[1,3]], # composite
               params$summary_table[[2,2]], # AC
               params$summary_table[[7,2]],
               readr::parse_number(params$summary_table[[8,2]])
             )
             ),
             stim = params$stim,
             scoring = "dalton_richardson",
             norm_var = "AC_min",
             basesize=11)
message("p4 done")

plots <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)

legend <- cowplot::get_legend(
  p1 + 
    ggplot2::guides(color = ggplot2::guide_legend(nrow = 1)) +
    ggplot2::theme(legend.position = "bottom")
)
shiny::setProgress(0.5)

cowplot::plot_grid(plots, legend, ncol=1, rel_heights = c(1, .1))
```

**About these plots:**

- *The figure shows two density plots that represent the distribution of the discourse variables. (A density plot is essentially a smoothed version of a histogram.)*

- *The orange plot is the density plot for persons with aphasia. The purple plot is the density plot for controls. (These plots closely correspond to the values in our publications [Richardson & Dalton, 2015, 2019; Dalton & Richardson, 2018; Dalton et al., 2020], but are updated several times a year with additional participants scored in Dr. Richardson’s lab.)*

- *The vertical red dashed line represents the discourse variable score for your patient/participant. You can select different discourse variables (Composite, AC, Attempts, AC/min) by selecting the variable of interest below the plots.*

### Administration notes 

*If notes were entered prior to scoring, they will appear below*

```{r, echo = F, results = 'asis'}
shiny::setProgress(0.8)

#cat(params$notes)
shiny::setProgress(0.9)
```


### References

Nicholas, L. E., & Brookshire, R. H. (1995). Presence, completeness, and accuracy of main concepts in the connected speech of non-brain-damaged adults and adults with aphasia. Journal of Speech, Language, and Hearing Research, 38(1), 145-156.

Richardson, J. D., & Dalton, S. G. (2016). Main concepts for three different discourse tasks in a large non-clinical sample. Aphasiology, 30(1), 45-73.

Richardson, J. D., & Dalton, S. G. H. (2020). Main concepts for two picture description tasks: an addition to Richardson and Dalton, 2016. Aphasiology, 34(1), 119-136.

### About this report

This report was generated by the mainConcept shiny web app located at https://aphasia-apps.shinyapps.io/mainConcept/. This web-app is open source and the source code is located at https://github.com/aphasia-apps/mainConcept. Comments, feedback, and bug-reports are encouraged and can be made on the github page. The app was developed by Robert Cavanaugh, Jessica Richardson, and Sarah Grace Dalton. 

This software can be cited as such:

Cavanaugh, R., Richardson, J. & Dalton, S.G. (2021). mainConcept: An open-source web-app for scoring main concept analysis. R package version 0.0.1.0000. https://github.com/aphasia-apps/mainConcept.

```{r, echo = F}
shiny::setProgress(0.95)
```

